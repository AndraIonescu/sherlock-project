{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features, retrain Sherlock and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below first downloads the data (roughly 700K samples), then extract features from the raw data values. <br>\n",
    "If you want to skip this step, you can follow the steps below the feature extraction to load the preprocessed data, \n",
    "retrain Sherlock and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import build_features\n",
    "from src.features.build_features import _get_data\n",
    "from src.deploy.train_sherlock import train_sherlock\n",
    "from src.deploy.predict_sherlock import predict_sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data; the original raw values and preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw data values (skip these steps if you want to take the preprocessed data, then scroll down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = pd.read_parquet('../data/raw/train_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = pd.read_parquet('../data/raw/train_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vals = pd.read_parquet('../data/raw/val_values.parquet')\n",
    "val_labs = pd.read_parquet('../data/raw/val_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vals = pd.read_parquet('../data/raw/test_values.parquet')\n",
    "test_labs = pd.read_parquet('../data/raw/test_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>['Central Missouri', 'unattached', 'unattached...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>[95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366813</th>\n",
       "      <td>['Katie Crews', 'Christian Hiraldo', 'Alex Est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530567</th>\n",
       "      <td>['Christian', 'Non-Christian', 'Unreported', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176253</th>\n",
       "      <td>['AAF-McQuay Canada Inc.', 'AAF-McQuay Canada ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   values\n",
       "20368   ['Central Missouri', 'unattached', 'unattached...\n",
       "664102  [95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...\n",
       "366813  ['Katie Crews', 'Christian Hiraldo', 'Alex Est...\n",
       "530567  ['Christian', 'Non-Christian', 'Unreported', '...\n",
       "176253  ['AAF-McQuay Canada Inc.', 'AAF-McQuay Canada ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366813</th>\n",
       "      <td>jockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530567</th>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176253</th>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               type\n",
       "20368   affiliation\n",
       "664102       weight\n",
       "366813       jockey\n",
       "530567     religion\n",
       "176253      company"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = train_vals['values'].apply(literal_eval)\n",
    "val_vals = val_vals['values'].apply(literal_eval)\n",
    "test_vals = test_vals['values'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55030                    [Global, United States, Australia]\n",
       "167000    [Fiction, Adult - Non-Floating, Fiction, Adult...\n",
       "638282    [, , University of Puerto Rico - Rio Piedras, ...\n",
       "232298    [Laughology, MTV, With Intent to Kill, Comedy ...\n",
       "316158    [Mare, Gelding, Gelding, Gelding, Gelding, Mar...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 3 files: \n",
      " ../src/features/glove.6B.50d.txt, \n",
      " ../src/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy and \n",
      " ../data_fake/data_fake.zip.\n",
      "GloVe word embedding vectors were downloaded.\n",
      "Trained paragraph vector model was downloaded.\n",
      "Downloading data directory.\n",
      "Downloading 1-caOvAP5IB_QMqw4Jx5RO4xOsFliEC3Q into ../data_fake/data_fake.zip... \n",
      "0.0 B Done.\n",
      "Unzipping...Done.\n",
      "Data was downloaded.\n",
      "Extracting features for data column  100\n",
      "Extracting features for data column  200\n",
      "Extracting features for data column  300\n",
      "Extracting features for data column  400\n",
      "Extracting features for data column  500\n",
      "Extracting features for data column  600\n",
      "Extracting features for data column  700\n",
      "Extracting features for data column  800\n",
      "Extracting features for data column  900\n",
      "Extracting features for data column  1000\n",
      "Extracting features for data column  1100\n",
      "Extracting features for data column  1200\n",
      "Extracting features for data column  1300\n",
      "Extracting features for data column  1400\n",
      "Extracting features for data column  1500\n",
      "Extracting features for data column  1600\n",
      "Extracting features for data column  1700\n",
      "Extracting features for data column  1800\n",
      "Extracting features for data column  1900\n",
      "Extracting features for data column  2000\n",
      "Extracting features for data column  2100\n",
      "Extracting features for data column  2200\n",
      "Extracting features for data column  2300\n",
      "Extracting features for data column  2400\n",
      "Extracting features for data column  2500\n",
      "Extracting features for data column  2600\n",
      "Extracting features for data column  2700\n",
      "Extracting features for data column  2800\n",
      "Extracting features for data column  2900\n",
      "Extracting features for data column  3000\n",
      "Extracting features for data column  3100\n",
      "Extracting features for data column  3200\n",
      "Extracting features for data column  3300\n",
      "Extracting features for data column  3400\n",
      "Extracting features for data column  3500\n",
      "Extracting features for data column  3600\n",
      "Extracting features for data column  3700\n",
      "Extracting features for data column  3800\n",
      "Extracting features for data column  3900\n",
      "Extracting features for data column  4000\n",
      "Extracting features for data column  4100\n",
      "Extracting features for data column  4200\n",
      "Extracting features for data column  4300\n",
      "Extracting features for data column  4400\n",
      "Extracting features for data column  4500\n",
      "Extracting features for data column  4600\n",
      "Extracting features for data column  4700\n",
      "Extracting features for data column  4800\n",
      "Extracting features for data column  4900\n",
      "Extracting features for data column  5000\n",
      "Extracting features for data column  5100\n",
      "Extracting features for data column  5200\n",
      "Extracting features for data column  5300\n",
      "Extracting features for data column  5400\n",
      "Extracting features for data column  5500\n",
      "Extracting features for data column  5600\n",
      "Extracting features for data column  5700\n",
      "Extracting features for data column  5800\n",
      "Extracting features for data column  5900\n",
      "Extracting features for data column  6000\n",
      "Extracting features for data column  6100\n",
      "Extracting features for data column  6200\n",
      "Extracting features for data column  6300\n",
      "Extracting features for data column  6400\n",
      "Extracting features for data column  6500\n",
      "Extracting features for data column  6600\n",
      "Extracting features for data column  6700\n",
      "Extracting features for data column  6800\n"
     ]
    }
   ],
   "source": [
    "X_train = build_features(train_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_parquet('X_train_13.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labs.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = build_features(val_labs)\n",
    "X_test = build_features(test_labs)\n",
    "y_val = val_labs.values.flatten()\n",
    "y_test = test_labs.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaN values with feature means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train.mean()).transpose().to_csv('train_column_means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns_means = pd.read_csv('train_column_means.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(train_columns_means.iloc[0], inplace=True)\n",
    "X_val.fillna(train_columns_means.iloc[0], inplace=True)\n",
    "X_test.fillna(train_columns_means.iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train sherlock\n",
    "Don't retrain with `nn_id='sherlock'` to avoid overwriting the original Sherlock model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sherlock(X_train, y_train, X_val, y_val, nn_id='retrain_sherlock');\n",
    "print('Trained and saved new model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions with the retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test, nn_id='retrain_sherlock')\n",
    "print('Predicted labels: ', predicted_labels, 'true labels: ', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, predicted_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions with preprocessed data using Sherlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = pd.read_parquet('../data/processed/X_test.parquet')\n",
    "y_test_preprocessed = pd.read_parquet('../data/processed/y_test.parquet').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_entropy</th>\n",
       "      <th>frac_unique</th>\n",
       "      <th>frac_numcells</th>\n",
       "      <th>frac_textcells</th>\n",
       "      <th>avg_num_cells</th>\n",
       "      <th>std_num_cells</th>\n",
       "      <th>avg_text_cells</th>\n",
       "      <th>std_text_cells</th>\n",
       "      <th>avg_spec_cells</th>\n",
       "      <th>std_spec_cells</th>\n",
       "      <th>...</th>\n",
       "      <th>par_vec_390</th>\n",
       "      <th>par_vec_391</th>\n",
       "      <th>par_vec_392</th>\n",
       "      <th>par_vec_393</th>\n",
       "      <th>par_vec_394</th>\n",
       "      <th>par_vec_395</th>\n",
       "      <th>par_vec_396</th>\n",
       "      <th>par_vec_397</th>\n",
       "      <th>par_vec_398</th>\n",
       "      <th>par_vec_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.122181</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.290</td>\n",
       "      <td>5.077194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>-0.029472</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.090851</td>\n",
       "      <td>-0.125505</td>\n",
       "      <td>-0.027747</td>\n",
       "      <td>0.028412</td>\n",
       "      <td>-0.078901</td>\n",
       "      <td>0.054292</td>\n",
       "      <td>-0.049115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.817487</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.058</td>\n",
       "      <td>0.233743</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244085</td>\n",
       "      <td>-0.055574</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.079978</td>\n",
       "      <td>-0.014825</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.121871</td>\n",
       "      <td>-0.078689</td>\n",
       "      <td>-0.069111</td>\n",
       "      <td>-0.112550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.166061</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>11.527</td>\n",
       "      <td>2.688730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>-0.088117</td>\n",
       "      <td>-0.048036</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>-0.109643</td>\n",
       "      <td>-0.070223</td>\n",
       "      <td>-0.009666</td>\n",
       "      <td>-0.081991</td>\n",
       "      <td>-0.041528</td>\n",
       "      <td>-0.094458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.316887</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.053</td>\n",
       "      <td>1.960151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063415</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>-0.033859</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>0.075499</td>\n",
       "      <td>-0.009511</td>\n",
       "      <td>-0.070606</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.065065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.955528</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.531804</td>\n",
       "      <td>20.268</td>\n",
       "      <td>9.593132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>-0.213604</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>-0.009626</td>\n",
       "      <td>-0.154028</td>\n",
       "      <td>-0.090470</td>\n",
       "      <td>-0.013950</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>-0.139673</td>\n",
       "      <td>-0.115430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_entropy  frac_unique  frac_numcells  frac_textcells  avg_num_cells  \\\n",
       "0     2.122181        0.005          0.000             1.0          0.000   \n",
       "1     3.817487        0.015          1.000             0.0          2.058   \n",
       "2     3.166061        0.009          0.120             1.0          0.120   \n",
       "3     2.316887        0.005          0.000             1.0          0.000   \n",
       "4     6.955528        0.163          0.018             1.0          0.072   \n",
       "\n",
       "   std_num_cells  avg_text_cells  std_text_cells  avg_spec_cells  \\\n",
       "0       0.000000          12.290        5.077194             0.0   \n",
       "1       0.233743           0.000        0.000000             0.0   \n",
       "2       0.324962          11.527        2.688730             0.0   \n",
       "3       0.000000           9.053        1.960151             0.0   \n",
       "4       0.531804          20.268        9.593132             0.0   \n",
       "\n",
       "   std_spec_cells  ...  par_vec_390  par_vec_391  par_vec_392  par_vec_393  \\\n",
       "0             0.0  ...     0.023563    -0.029472     0.002835     0.090851   \n",
       "1             0.0  ...     0.244085    -0.055574     0.017600     0.079978   \n",
       "2             0.0  ...     0.018266    -0.088117    -0.048036    -0.011286   \n",
       "3             0.0  ...    -0.063415    -0.000197     0.012020    -0.033859   \n",
       "4             0.0  ...     0.015399    -0.213604     0.029100    -0.009626   \n",
       "\n",
       "   par_vec_394  par_vec_395  par_vec_396  par_vec_397  par_vec_398  \\\n",
       "0    -0.125505    -0.027747     0.028412    -0.078901     0.054292   \n",
       "1    -0.014825     0.006086     0.121871    -0.078689    -0.069111   \n",
       "2    -0.109643    -0.070223    -0.009666    -0.081991    -0.041528   \n",
       "3     0.063092     0.075499    -0.009511    -0.070606     0.061907   \n",
       "4    -0.154028    -0.090470    -0.013950     0.036592    -0.139673   \n",
       "\n",
       "   par_vec_399  \n",
       "0    -0.049115  \n",
       "1    -0.112550  \n",
       "2    -0.094458  \n",
       "3     0.065065  \n",
       "4    -0.115430  \n",
       "\n",
       "[5 rows x 1588 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511600</th>\n",
       "      <td>affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146358</th>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665579</th>\n",
       "      <td>jockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148486</th>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "index              \n",
       "511600  affiliation\n",
       "146358       weight\n",
       "665579       jockey\n",
       "148486     religion\n",
       "3546        company"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Sherlock with other than the preprocessed data files might yield inconsistent results due to a changed feature extraction pipeline. <br> \n",
    "The model will be retrained with data consistent with the new feature extraction pipeline soon. <br>\n",
    "For now the preprocessed train, validation and test data can be used to reproduce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test_preprocessed, 'sherlock')\n",
    "print('Predicted labels: ', predicted_labels, 'true labels: ', y_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test_preprocessed, predicted_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
