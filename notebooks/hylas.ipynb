{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hylas - custom prediction using Sherlock methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data sets from extracted CSV product column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treating file data with 8 cores\n",
      "Processing \"product_brandGender2\"\n",
      "Processing \"product_ageGroup1\"\n",
      "Processing \"product_sportPurpose3\"\n",
      "Processing \"product_sportPurpose4\"\n",
      "Processing \"product_sportPurpose2\"\n",
      "Processing \"product_brandCategory4_footwear\"\n",
      "Processing \"article_brandColourName\"\n",
      "Processing \"product_brandCategory1\"\n",
      "Processing \"article_id\"\n",
      "Processing \"product_brandGender1\"\n",
      "Processing \"product_type\"\n",
      "Processing \"article_brandSize\"\n",
      "Processing \"product_ageGroup2\"\n",
      "Processing \"product_brandSeason\"\n",
      "Processing \"product_brandSizeGrid\"\n",
      "Processing \"product_sportPurpose1\"\n",
      "Processing \"product_primaryCategoryIdCode\"\n",
      "Processing \"product_id\"\n",
      "Processing \"product_brandCategory3\"\n",
      "Processing \"product_brandCategory2\"\n",
      "Saving to parquet\n",
      "Write process took 0:00:03.768062 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import pandas\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as pc\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def tryeval(val):\n",
    "  try:\n",
    "    val=literal_eval(val)\n",
    "  except (ValueError, SyntaxError):\n",
    "    pass\n",
    "  return val\n",
    "\n",
    "\n",
    "# Declare pool AFTER methods that will be later called from pool.\n",
    "pool = multiprocessing.Pool(os.cpu_count())\n",
    "\n",
    "\n",
    "pattern = re.compile(\"^(article|product)_\")\n",
    "\n",
    "by_key = '/Users/lowecg/mapped/attributes/brand-to-canonical/9/by-key'\n",
    "\n",
    "print(f'Treating file data with {os.cpu_count()} cores')\n",
    "\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "df_labels = pandas.DataFrame(columns=['type'])\n",
    "df_samples = pandas.DataFrame(columns=['values'])\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for file_name in os.listdir(by_key):\n",
    "  if pattern.match(file_name):\n",
    "    print(f'Processing \"{file_name}\"')\n",
    "    \n",
    "    with open (by_key + '/' + file_name, 'r') as attributes_file:\n",
    "      data=attributes_file.readlines()\n",
    "        \n",
    "      idx += 1      \n",
    "        \n",
    "      df_labels.loc[idx, 'type'] = file_name\n",
    "    \n",
    "      unique = list(pool.map(str.strip, set(data)))\n",
    "        \n",
    "      to_store = str(list(pool.map(tryeval, unique)))\n",
    "    \n",
    "      df_samples.loc[idx, 'values'] = to_store\n",
    "        \n",
    "  else:\n",
    "    print('IGNORED: ', file_name)\n",
    "\n",
    "    \n",
    "print('Saving to parquet')\n",
    "    \n",
    "df_labels.to_parquet(fname='myfile_labels.parquet',engine='auto',compression='snappy')\n",
    "df_samples.to_parquet(fname='myfile_values.parquet',engine='auto',compression='snappy')\n",
    "\n",
    "end = datetime.now()\n",
    "x = end - start\n",
    "print(f'Write process took {x} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataframe task (myfile_samples):  2021-01-01 15:44:04.174916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('Creating dataframe task (myfile_samples): ', datetime.now())\n",
    "\n",
    "myfile_labels = pd.read_parquet('myfile_labels.parquet')\n",
    "myfile_samples = pd.read_parquet('myfile_values.parquet')\n",
    "\n",
    "#print('Starting task (myfile_samples): ', datetime.now())\n",
    "\n",
    "# this operation is now handled by convert_string_lists_to_lists in a later step\n",
    "#myfile_samples = myfile_samples['values'].apply(literal_eval)\n",
    "\n",
    "#print('Finished task (myfile_samples): ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_brandGender2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_ageGroup1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_sportPurpose3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_sportPurpose4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>product_sportPurpose2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>product_brandCategory4_footwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>article_brandColourName</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>product_brandCategory1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>article_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>product_brandGender1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>product_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>article_brandSize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product_ageGroup2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product_brandSeason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>product_brandSizeGrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product_sportPurpose1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>product_primaryCategoryIdCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>product_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>product_brandCategory3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>product_brandCategory2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               type\n",
       "1              product_brandGender2\n",
       "2                 product_ageGroup1\n",
       "3             product_sportPurpose3\n",
       "4             product_sportPurpose4\n",
       "5             product_sportPurpose2\n",
       "6   product_brandCategory4_footwear\n",
       "7           article_brandColourName\n",
       "8            product_brandCategory1\n",
       "9                        article_id\n",
       "10             product_brandGender1\n",
       "11                     product_type\n",
       "12                article_brandSize\n",
       "13                product_ageGroup2\n",
       "14              product_brandSeason\n",
       "15            product_brandSizeGrid\n",
       "16            product_sportPurpose1\n",
       "17    product_primaryCategoryIdCode\n",
       "18                       product_id\n",
       "19           product_brandCategory3\n",
       "20           product_brandCategory2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile_labels.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['KU', 'Infants', 'Boys', 'Girls', 'Kids Unisex']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['W', 'U', 'Unisex', 'Women', 'Men', 'M', 'Kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Netball', 'Volleyball', 'Skateboarding', 'Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Winter Sports', 'HIIT', 'Training', 'Handbal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['Volleyball', 'Skateboarding', 'Running', 'Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['Y-3', 'adidas neo', 'Classics', 'adidas TERR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['Dgh Solid Grey/Gun Metallic', 'Scarlet / Whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['Clothing', 'Accessories', 'Shoes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[4059812314870, 4055014279801, 4054706518259, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['W', 'U', 'Unisex', 'Women', 'Men', 'M', 'K',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['product-canonical']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['48\"S', '42D', '13K', 6, 'M/L', '34/36 (S)', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['KU', 'Infants', 'Boys', 'Girls', 'Kids Unisex']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['SS15', 'FW19', 'FW17', 'FW14', 'FW16', 'FW18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['size-kb_5-16y', 'size-hats', 'size-kg_5-15y'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['Track and Field', 'Volleyball', 'Badminton',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['Clothing', 'Accessories', 'Shoes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['GD8721', 'F80184', 'M69535', 'S18689', 'AJ76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['T-Shirts', 'Hoodies', 'Sweatpants &amp;#38; Tigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['Swim Shorts &amp; Board Shorts', 'Fleece Jackets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               values\n",
       "1   ['KU', 'Infants', 'Boys', 'Girls', 'Kids Unisex']\n",
       "2   ['W', 'U', 'Unisex', 'Women', 'Men', 'M', 'Kid...\n",
       "3   ['Netball', 'Volleyball', 'Skateboarding', 'Wa...\n",
       "4   ['Winter Sports', 'HIIT', 'Training', 'Handbal...\n",
       "5   ['Volleyball', 'Skateboarding', 'Running', 'Wa...\n",
       "6   ['Y-3', 'adidas neo', 'Classics', 'adidas TERR...\n",
       "7   ['Dgh Solid Grey/Gun Metallic', 'Scarlet / Whi...\n",
       "8                ['Clothing', 'Accessories', 'Shoes']\n",
       "9   [4059812314870, 4055014279801, 4054706518259, ...\n",
       "10  ['W', 'U', 'Unisex', 'Women', 'Men', 'M', 'K',...\n",
       "11                              ['product-canonical']\n",
       "12  ['48\"S', '42D', '13K', 6, 'M/L', '34/36 (S)', ...\n",
       "13  ['KU', 'Infants', 'Boys', 'Girls', 'Kids Unisex']\n",
       "14  ['SS15', 'FW19', 'FW17', 'FW14', 'FW16', 'FW18...\n",
       "15  ['size-kb_5-16y', 'size-hats', 'size-kg_5-15y'...\n",
       "16  ['Track and Field', 'Volleyball', 'Badminton',...\n",
       "17               ['Clothing', 'Accessories', 'Shoes']\n",
       "18  ['GD8721', 'F80184', 'M69535', 'S18689', 'AJ76...\n",
       "19  ['T-Shirts', 'Hoodies', 'Sweatpants &#38; Tigh...\n",
       "20  ['Swim Shorts & Board Shorts', 'Fleece Jackets..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile_samples.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.features.preprocessing import extract_features, convert_string_lists_to_lists, prepare_feature_extraction\n",
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "It is important that the string-representations of lists are first converted into lists of strings.\n",
    "The labels should be a list of semantic types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "test_samples_converted, y_test = convert_string_lists_to_lists(myfile_samples, myfile_labels, \"values\", \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1              [KU, Infants, Boys, Girls, Kids Unisex]\n",
       "2               [W, U, Unisex, Women, Men, M, Kids, K]\n",
       "3    [Netball, Volleyball, Skateboarding, Walking, ...\n",
       "4    [Winter Sports, HIIT, Training, Handball, Urba...\n",
       "5    [Volleyball, Skateboarding, Running, Walking, ...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples_converted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given that feature extraction can take long, we only take the first 100 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_subset = y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n",
      "Initialising word embeddings\n",
      "Initialise Word Embeddings process took 0:00:05.834454 seconds.\n",
      "Initialise Doc2Vec Model, 400 dim, process took 0:00:02.292727 seconds. (filename = ../sherlock/features/par_vec_retrained_400.pkl)\n",
      "Initialised NLTK, process took 0:00:00.158073 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lowecg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lowecg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ensure embedding initialisation is outside of timing for extract_features\n",
    "from sherlock.features.word_embeddings import initialise_word_embeddings\n",
    "from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk\n",
    "from sherlock.features.preprocessing import prepare_feature_extraction\n",
    "\n",
    "prepare_feature_extraction()\n",
    "initialise_word_embeddings()\n",
    "initialise_pretrained_model(400)\n",
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  75%|███████▌  | 15/20 [00:00<00:00, 60.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 1578 column features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Extracting Features: 100%|██████████| 20/20 [00:00<00:00, 74.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Features process took 0:00:00.320845 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "%lprun -m sherlock.features.preprocessing X_test=extract_features('output2.csv', test_samples_converted.head(n=100)) \n",
    "\n",
    "\n",
    "\n",
    "#X_test = extract_features('output.csv', test_samples_converted.head(n=100))\n",
    "\n",
    "end = datetime.now()\n",
    "x = end - start\n",
    "print(f'Extract Features process took {x} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline (before changes)\n",
    "# Extract Features process took 0:03:11.954844 seconds.\n",
    "\n",
    "# Tuning iterations\n",
    "# Extract Features process took 0:00:13.869183 seconds. (cache Word Embeddings)\n",
    "# Extract Features process took 0:00:06.143361 seconds. (cache Doc2Vec)\n",
    "# Extract Features process took 0:00:01.308678 seconds. (improved computation for bag of character features)\n",
    "# Extract Features process took 0:00:01.259591 seconds. (smaller optimisation tweaks - string cat, removal of double compute of some stats)\n",
    "# Extract Features process took 0:00:00.650005 seconds. (use arrays not pd.Series for stats, series.str.count is also inefficient compared to loops)\n",
    "# Extract Features process took 0:00:00.320845 seconds. (replace np stats calcs, unique values calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dca623968bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_orig = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig.equals(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "filename = \"htest_{timestr}.csv\".format(timestr = time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "X_test.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
