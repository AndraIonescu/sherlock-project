{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_id = 'retrained_sherlock8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2021-12-20 19:11:25.021252\n",
      "Load data (train) process took 0:00:09.589445 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('train.parquet')\n",
    "y_train = pd.read_parquet('../data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2021-12-20 19:11:34.635005\n",
      "Load data (validation) process took 0:00:02.410613 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([x.lower() for x in itertools.chain(y_train, y_validation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2021-12-20 19:11:41.404964\n",
      "Trained and saved new model.\n",
      "Finished at 2021-12-20 19:28:13.317631, took 0:16:31.914820 seconds\n"
     ]
    }
   ],
   "source": [
    "# n_estimators=300 gives a slightly better result (0.1%), but triples the fit time\n",
    "n_estimators=100\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=n_estimators, n_jobs=-1)\n",
    "\n",
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('rd', rnd_clf), ('et', et_clf)], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2021-12-20 19:28:13.510667\n",
      "Trained and saved new model.\n",
      "Finished at 2021-12-20 19:28:15.894303, took 0:00:02.383650 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('test.parquet')\n",
    "y_test = pd.read_parquet('../data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob = voting_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load(\n",
    "        f\"../sherlock/deploy/classes_{nn_model_id}.npy\",\n",
    "        allow_pickle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (classes == sorted(classes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1220 19:28:47.962548 4420566528 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1220 19:28:47.963889 4420566528 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1220 19:28:47.967644 4420566528 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1220 19:28:47.985634 4420566528 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "2021-12-20 19:28:48.568387: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-12-20 19:28:48.633041: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff08cad8470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-20 19:28:48.633059: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock_proba, _transform_predictions_to_classes\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "predict_sherlock_proba = predict_sherlock_proba(X_test, nn_id=nn_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    nn_probs = predict_sherlock_proba[i]\n",
    "    voting_probs = predicted_prob[i]\n",
    "    \n",
    "    x = nn_probs + voting_probs\n",
    "    x = x / 2\n",
    "\n",
    "    combined.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = _transform_predictions_to_classes(combined, nn_id=nn_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9057198185099099"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â 0.8914784495960828 RandomForestClassifier\n",
    "#Â 0.8888581433158012 ExtraTreesClassifier\n",
    "# 0.8939142078215914 VotingClassifier\n",
    "\n",
    "#Â 0.9051046508515834  NN + votingclassifier\n",
    "# 0.9037255679859006 RFC(100) + NN\n",
    "# 0.904082859543776 RFC(300) + NN\n",
    "\n",
    "# 0.905148377678918 NN + VotingClassifier(RFC100 + ETC100)\n",
    "#Â 0.9057069845572598 NN (retrained_sherlock8) + VotingClassifier(RFC300 + ETC300)\n",
    "\n",
    "# 0.9057005326978261 NN (retrained_sherlock8) + VotingClassifier(RFC100 + ETC100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "grades\t\t0.993\t\t0.990\t\t0.995\t\t1765\n",
      "isbn\t\t0.992\t\t0.995\t\t0.989\t\t1430\n",
      "jockey\t\t0.988\t\t0.987\t\t0.989\t\t2819\n",
      "industry\t0.984\t\t0.979\t\t0.990\t\t2958\n",
      "birth date\t0.978\t\t0.979\t\t0.977\t\t479\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "brand\t\t0.748\t\t0.783\t\t0.716\t\t574\n",
      "person\t\t0.687\t\t0.757\t\t0.629\t\t579\n",
      "sales\t\t0.644\t\t0.722\t\t0.581\t\t322\n",
      "director\t0.615\t\t0.709\t\t0.542\t\t225\n",
      "ranking\t\t0.596\t\t0.823\t\t0.467\t\t439\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       address      0.939     0.953     0.946      3003\n",
      "     affiliate      0.988     0.809     0.889       204\n",
      "   affiliation      0.983     0.954     0.968      1768\n",
      "           age      0.901     0.952     0.926      3033\n",
      "         album      0.885     0.906     0.895      3035\n",
      "          area      0.894     0.840     0.866      1987\n",
      "        artist      0.815     0.883     0.848      3043\n",
      "    birth date      0.979     0.977     0.978       479\n",
      "   birth place      0.982     0.902     0.940       418\n",
      "         brand      0.783     0.716     0.748       574\n",
      "      capacity      0.821     0.773     0.797       362\n",
      "      category      0.915     0.903     0.909      3087\n",
      "          city      0.837     0.919     0.876      2966\n",
      "         class      0.920     0.925     0.923      2971\n",
      "classification      0.946     0.869     0.906       587\n",
      "          club      0.976     0.960     0.968      2977\n",
      "          code      0.934     0.922     0.928      2956\n",
      "    collection      0.991     0.937     0.963       476\n",
      "       command      0.932     0.930     0.931      1045\n",
      "       company      0.902     0.905     0.904      3041\n",
      "     component      0.908     0.896     0.902      1226\n",
      "     continent      0.909     0.921     0.915       227\n",
      "       country      0.906     0.941     0.923      3038\n",
      "        county      0.936     0.961     0.949      2959\n",
      "       creator      0.907     0.839     0.871       347\n",
      "        credit      0.869     0.846     0.857       941\n",
      "      currency      0.982     0.968     0.975       405\n",
      "           day      0.955     0.910     0.932      3038\n",
      "         depth      0.954     0.940     0.947       947\n",
      "   description      0.825     0.882     0.853      3042\n",
      "      director      0.709     0.542     0.615       225\n",
      "      duration      0.938     0.954     0.946      3000\n",
      "     education      0.908     0.856     0.882       313\n",
      "     elevation      0.944     0.964     0.954      1299\n",
      "        family      0.975     0.903     0.938       746\n",
      "     file size      0.955     0.875     0.913       361\n",
      "        format      0.966     0.959     0.962      2956\n",
      "        gender      0.855     0.836     0.845      1030\n",
      "         genre      0.944     0.958     0.951      1163\n",
      "        grades      0.990     0.995     0.993      1765\n",
      "      industry      0.979     0.990     0.984      2958\n",
      "          isbn      0.995     0.989     0.992      1430\n",
      "        jockey      0.987     0.989     0.988      2819\n",
      "      language      0.869     0.947     0.906      1474\n",
      "      location      0.877     0.844     0.860      2949\n",
      "  manufacturer      0.884     0.819     0.850       945\n",
      "          name      0.744     0.769     0.756      3017\n",
      "   nationality      0.851     0.755     0.800       424\n",
      "         notes      0.760     0.845     0.800      2303\n",
      "      operator      0.866     0.849     0.858       404\n",
      "         order      0.875     0.875     0.875      1462\n",
      "  organisation      0.877     0.847     0.862       262\n",
      "        origin      0.970     0.898     0.933      1439\n",
      "         owner      0.945     0.874     0.908      1673\n",
      "        person      0.757     0.629     0.687       579\n",
      "         plays      0.824     0.922     0.871      1513\n",
      "      position      0.845     0.854     0.850      3057\n",
      "       product      0.890     0.880     0.885      2647\n",
      "     publisher      0.906     0.909     0.908       880\n",
      "         range      0.902     0.797     0.846       577\n",
      "          rank      0.712     0.797     0.752      2983\n",
      "       ranking      0.823     0.467     0.596       439\n",
      "        region      0.877     0.857     0.867      2740\n",
      "      religion      0.991     0.924     0.956       340\n",
      "   requirement      0.931     0.813     0.868       300\n",
      "        result      0.979     0.944     0.961      2920\n",
      "         sales      0.722     0.581     0.644       322\n",
      "       service      0.961     0.928     0.944      2222\n",
      "           sex      0.942     0.937     0.939      2997\n",
      "       species      0.944     0.944     0.944       819\n",
      "         state      0.949     0.957     0.953      3030\n",
      "        status      0.954     0.942     0.948      3100\n",
      "        symbol      0.953     0.974     0.963      1752\n",
      "          team      0.885     0.861     0.873      3011\n",
      "     team name      0.907     0.843     0.874      1639\n",
      "          type      0.897     0.890     0.894      2909\n",
      "        weight      0.952     0.949     0.950      2963\n",
      "          year      0.963     0.945     0.954      3015\n",
      "\n",
      "      accuracy                          0.906    137353\n",
      "     macro avg      0.905     0.881     0.891    137353\n",
      "  weighted avg      0.907     0.906     0.906    137353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches: 12946 (F1 score: 0.9057198185099099)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('name', 697),\n",
       " ('rank', 607),\n",
       " ('location', 461),\n",
       " ('position', 445),\n",
       " ('team', 418),\n",
       " ('region', 392),\n",
       " ('description', 360),\n",
       " ('artist', 357),\n",
       " ('notes', 357),\n",
       " ('type', 320),\n",
       " ('product', 318),\n",
       " ('area', 318),\n",
       " ('category', 299),\n",
       " ('company', 288),\n",
       " ('album', 286),\n",
       " ('day', 272),\n",
       " ('team name', 258),\n",
       " ('city', 240),\n",
       " ('ranking', 234),\n",
       " ('code', 230),\n",
       " ('class', 223),\n",
       " ('person', 215),\n",
       " ('owner', 211),\n",
       " ('sex', 190),\n",
       " ('order', 183),\n",
       " ('status', 180),\n",
       " ('country', 179),\n",
       " ('manufacturer', 171),\n",
       " ('gender', 169),\n",
       " ('year', 167),\n",
       " ('result', 164),\n",
       " ('brand', 163),\n",
       " ('service', 160),\n",
       " ('weight', 152),\n",
       " ('origin', 147),\n",
       " ('age', 145),\n",
       " ('credit', 145),\n",
       " ('address', 142),\n",
       " ('duration', 137),\n",
       " ('sales', 135),\n",
       " ('state', 131),\n",
       " ('component', 127),\n",
       " ('format', 122),\n",
       " ('club', 119),\n",
       " ('plays', 118),\n",
       " ('range', 117),\n",
       " ('county', 114),\n",
       " ('nationality', 104),\n",
       " ('director', 103),\n",
       " ('affiliation', 82),\n",
       " ('capacity', 82),\n",
       " ('publisher', 80),\n",
       " ('language', 78),\n",
       " ('classification', 77),\n",
       " ('command', 73),\n",
       " ('family', 72),\n",
       " ('operator', 61),\n",
       " ('depth', 57),\n",
       " ('creator', 56),\n",
       " ('requirement', 56),\n",
       " ('genre', 49),\n",
       " ('elevation', 47),\n",
       " ('species', 46),\n",
       " ('symbol', 46),\n",
       " ('education', 45),\n",
       " ('file size', 45),\n",
       " ('birth place', 41),\n",
       " ('organisation', 40),\n",
       " ('affiliate', 39),\n",
       " ('industry', 31),\n",
       " ('collection', 30),\n",
       " ('jockey', 30),\n",
       " ('religion', 26),\n",
       " ('continent', 18),\n",
       " ('isbn', 16),\n",
       " ('currency', 13),\n",
       " ('birth date', 11),\n",
       " ('grades', 9)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "#        if k1 in ('brand'):\n",
    "#        print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"age\", actual label \"position\". Actual values:\n",
      "[[2, 4]]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "idx = 541\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
