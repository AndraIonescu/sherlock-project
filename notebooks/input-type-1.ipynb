{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hylas (TYPE 1) - custom prediction using Sherlock methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data sets from extracted CSV product column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treating file data with 8 cores\n",
      "Processing \"product_brandGender2\"\n",
      "Processing \"product_ageGroup1\"\n",
      "Processing \"product_sportPurpose3\"\n",
      "Processing \"product_sportPurpose4\"\n",
      "Processing \"product_sportPurpose2\"\n",
      "Processing \"product_brandCategory4_footwear\"\n",
      "Processing \"article_brandColourName\"\n",
      "Processing \"product_brandCategory1\"\n",
      "Processing \"article_id\"\n",
      "Processing \"product_brandGender1\"\n",
      "Processing \"product_type\"\n",
      "Processing \"article_brandSize\"\n",
      "Processing \"product_ageGroup2\"\n",
      "Processing \"product_brandSeason\"\n",
      "Processing \"product_brandSizeGrid\"\n",
      "Processing \"product_sportPurpose1\"\n",
      "Processing \"product_primaryCategoryIdCode\"\n",
      "Processing \"product_id\"\n",
      "Processing \"product_brandCategory3\"\n",
      "Processing \"product_brandCategory2\"\n",
      "Saving to parquet\n",
      "Write process took 0:00:10.109004 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import pandas\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as pc\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def tryeval(val):\n",
    "  try:\n",
    "    val=literal_eval(val)\n",
    "  except (ValueError, SyntaxError):\n",
    "    pass\n",
    "  return val\n",
    "\n",
    "\n",
    "# Declare pool AFTER methods that will be later called from pool.\n",
    "pool = multiprocessing.Pool(os.cpu_count())\n",
    "\n",
    "\n",
    "pattern = re.compile(\"^(article|product)_\")\n",
    "\n",
    "by_key = '/Users/lowecg/mapped/attributes/brand-to-canonical/9/by-key'\n",
    "\n",
    "print(f'Treating file data with {os.cpu_count()} cores')\n",
    "\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "df_labels = pandas.DataFrame(columns=['type'])\n",
    "df_samples = pandas.DataFrame(columns=['values'])\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for file_name in os.listdir(by_key):\n",
    "  if pattern.match(file_name):\n",
    "    print(f'Processing \"{file_name}\"')\n",
    "    \n",
    "    with open (by_key + '/' + file_name, 'r') as attributes_file:\n",
    "      data=attributes_file.readlines()\n",
    "        \n",
    "      idx += 1      \n",
    "        \n",
    "      df_labels.loc[idx, 'type'] = file_name\n",
    "\n",
    "      to_store = str(list(pool.map(tryeval, map(str.strip, data))))\n",
    "    \n",
    "      df_samples.loc[idx, 'values'] = to_store\n",
    "        \n",
    "  else:\n",
    "    print('IGNORED: ', file_name)\n",
    "\n",
    "    \n",
    "print('Saving to parquet')\n",
    "    \n",
    "df_labels.to_parquet(fname='myfile_labels.parquet',engine='auto',compression='snappy')\n",
    "df_samples.to_parquet(fname='myfile_values.parquet',engine='auto',compression='snappy')\n",
    "\n",
    "end = datetime.now()\n",
    "x = end - start\n",
    "print(f'Write process took {x} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataframe task (myfile_samples):  2021-02-09 12:05:44.696978\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('Creating dataframe task (myfile_samples): ', datetime.now())\n",
    "\n",
    "myfile_labels = pd.read_parquet('myfile_labels.parquet')\n",
    "myfile_samples = pd.read_parquet('myfile_values.parquet')\n",
    "\n",
    "#print('Starting task (myfile_samples): ', datetime.now())\n",
    "\n",
    "# this operation is now handled by convert_string_lists_to_lists in a later step\n",
    "#myfile_samples = myfile_samples['values'].apply(literal_eval)\n",
    "\n",
    "#print('Finished task (myfile_samples): ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_brandGender2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_ageGroup1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_sportPurpose3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_sportPurpose4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>product_sportPurpose2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>product_brandCategory4_footwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>article_brandColourName</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>product_brandCategory1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>article_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>product_brandGender1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>product_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>article_brandSize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product_ageGroup2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product_brandSeason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>product_brandSizeGrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product_sportPurpose1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>product_primaryCategoryIdCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>product_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>product_brandCategory3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>product_brandCategory2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               type\n",
       "1              product_brandGender2\n",
       "2                 product_ageGroup1\n",
       "3             product_sportPurpose3\n",
       "4             product_sportPurpose4\n",
       "5             product_sportPurpose2\n",
       "6   product_brandCategory4_footwear\n",
       "7           article_brandColourName\n",
       "8            product_brandCategory1\n",
       "9                        article_id\n",
       "10             product_brandGender1\n",
       "11                     product_type\n",
       "12                article_brandSize\n",
       "13                product_ageGroup2\n",
       "14              product_brandSeason\n",
       "15            product_brandSizeGrid\n",
       "16            product_sportPurpose1\n",
       "17    product_primaryCategoryIdCode\n",
       "18                       product_id\n",
       "19           product_brandCategory3\n",
       "20           product_brandCategory2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile_labels.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['KU', 'Girls', 'Kids Unisex', 'Boys', 'Boys',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['M', 'K', 'W', 'Women', 'W', 'W', 'Women', 'W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Yoga', 'Yoga', 'Skateboarding', 'Training', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Yoga', 'Winter Sports', 'Studio', 'Tennis', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['Running', 'Training', 'Yoga', 'Training', 'Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['Performance', 'Performance', 'Performance', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['White', 'White', 'White', 'White', 'White', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['Clothing', 'Shoes', 'Clothing', 'Clothing', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[4056562624693, 4056562625324, 4056562625379, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['M', 'M', 'K', 'Men', 'Men', 'M', 'M', 'Men',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['product-canonical', 'product-canonical', 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['XS', 'S', 'M', 'L', 'XL', '2XL', '3XL', '4XL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['KU', 'Girls', 'Kids Unisex', 'Boys', 'Boys',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['SS16', 'FW17', 'SS20', 'FW16', 'FW18', 'FW17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['size-m_bottoms', 'size-shoes', 'size-m_tops'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['Lifestyle', 'Training', 'Golf', 'Lifestyle',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['Clothing', 'Clothing', 'Clothing', 'Shoes', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['S93310', 'BA7934', 'EK1320', 'BZ0554', 'AE36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['Sport Shoes', 'Lifestyle Trainers', 'Trainer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['Short Sleeves', 'Sports Shorts', 'Vests', 'G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               values\n",
       "1   ['KU', 'Girls', 'Kids Unisex', 'Boys', 'Boys',...\n",
       "2   ['M', 'K', 'W', 'Women', 'W', 'W', 'Women', 'W...\n",
       "3   ['Yoga', 'Yoga', 'Skateboarding', 'Training', ...\n",
       "4   ['Yoga', 'Winter Sports', 'Studio', 'Tennis', ...\n",
       "5   ['Running', 'Training', 'Yoga', 'Training', 'Y...\n",
       "6   ['Performance', 'Performance', 'Performance', ...\n",
       "7   ['White', 'White', 'White', 'White', 'White', ...\n",
       "8   ['Clothing', 'Shoes', 'Clothing', 'Clothing', ...\n",
       "9   [4056562624693, 4056562625324, 4056562625379, ...\n",
       "10  ['M', 'M', 'K', 'Men', 'Men', 'M', 'M', 'Men',...\n",
       "11  ['product-canonical', 'product-canonical', 'pr...\n",
       "12  ['XS', 'S', 'M', 'L', 'XL', '2XL', '3XL', '4XL...\n",
       "13  ['KU', 'Girls', 'Kids Unisex', 'Boys', 'Boys',...\n",
       "14  ['SS16', 'FW17', 'SS20', 'FW16', 'FW18', 'FW17...\n",
       "15  ['size-m_bottoms', 'size-shoes', 'size-m_tops'...\n",
       "16  ['Lifestyle', 'Training', 'Golf', 'Lifestyle',...\n",
       "17  ['Clothing', 'Clothing', 'Clothing', 'Shoes', ...\n",
       "18  ['S93310', 'BA7934', 'EK1320', 'BZ0554', 'AE36...\n",
       "19  ['Sport Shoes', 'Lifestyle Trainers', 'Trainer...\n",
       "20  ['Short Sleeves', 'Sports Shorts', 'Vests', 'G..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile_samples.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "from sherlock import helpers\n",
    "#from sherlock.features.preprocessing import extract_features, convert_string_lists_to_lists, prepare_feature_extraction\n",
    "from sherlock.functional import extract_features_to_csv\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "It is important that the string-representations of lists are first converted into lists of strings.\n",
    "The labels should be a list of semantic types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given that feature extraction can take long, we only take the first 100 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_subset = y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n",
      "Initialising word embeddings\n",
      "Initialise Word Embeddings process took 0:00:06.461108 seconds.\n",
      "Initialise Doc2Vec Model, 400 dim, process took 0:00:02.776021 seconds. (filename = ../sherlock/features/par_vec_retrained_400.pkl)\n",
      "Initialised NLTK, process took 0:00:00.140686 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lowecg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lowecg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ensure embedding initialisation is outside of timing for extract_features\n",
    "from sherlock.features.word_embeddings import initialise_word_embeddings\n",
    "from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk\n",
    "from sherlock.features.preprocessing import prepare_feature_extraction\n",
    "\n",
    "prepare_feature_extraction()\n",
    "initialise_word_embeddings()\n",
    "initialise_pretrained_model(400)\n",
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1     ['KU', 'Girls', 'Kids Unisex', 'Boys', 'Boys',...\n",
      "2     ['M', 'K', 'W', 'Women', 'W', 'W', 'Women', 'W...\n",
      "3     ['Yoga', 'Yoga', 'Skateboarding', 'Training', ...\n",
      "4     ['Yoga', 'Winter Sports', 'Studio', 'Tennis', ...\n",
      "5     ['Running', 'Training', 'Yoga', 'Training', 'Y...\n",
      "6     ['Performance', 'Performance', 'Performance', ...\n",
      "7     ['White', 'White', 'White', 'White', 'White', ...\n",
      "8     ['Clothing', 'Shoes', 'Clothing', 'Clothing', ...\n",
      "9     [4056562624693, 4056562625324, 4056562625379, ...\n",
      "10    ['M', 'M', 'K', 'Men', 'Men', 'M', 'M', 'Men',...\n",
      "11    ['product-canonical', 'product-canonical', 'pr...\n",
      "12    ['XS', 'S', 'M', 'L', 'XL', '2XL', '3XL', '4XL...\n",
      "13    ['KU', 'Girls', 'Kids Unisex', 'Boys', 'Boys',...\n",
      "14    ['SS16', 'FW17', 'SS20', 'FW16', 'FW18', 'FW17...\n",
      "15    ['size-m_bottoms', 'size-shoes', 'size-m_tops'...\n",
      "16    ['Lifestyle', 'Training', 'Golf', 'Lifestyle',...\n",
      "17    ['Clothing', 'Clothing', 'Clothing', 'Shoes', ...\n",
      "18    ['S93310', 'BA7934', 'EK1320', 'BZ0554', 'AE36...\n",
      "19    ['Sport Shoes', 'Lifestyle Trainers', 'Trainer...\n",
      "20    ['Short Sleeves', 'Sports Shorts', 'Vests', 'G...\n",
      "Name: values, dtype: object\n",
      "Starting output2.csv at 2021-02-09 12:05:58.723938. Rows=20\n",
      "Exporting 1578 column features\n",
      "Finished. Processed 20 rows in 0:00:04.027386, key_count=1\n",
      "Extract Features process took 0:00:04.174279 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "print(f'processing {myfile_samples[\"values\"]}')\n",
    "\n",
    "#%lprun -m sherlock.features.preprocessing extract_features_to_csv('output2.csv', myfile_samples.head(n=100))\n",
    "extract_features_to_csv('output2.csv', myfile_samples[\"values\"].head(n=100))\n",
    "\n",
    "\n",
    "#X_test = extract_features('output.csv', test_samples_converted.head(n=100))\n",
    "\n",
    "end = datetime.now()\n",
    "x = end - start\n",
    "print(f'Extract Features process took {x} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline (before changes)\n",
    "# Extract Features process took 0:03:11.954844 seconds.\n",
    "\n",
    "# Tuning iterations\n",
    "# Extract Features process took 0:00:13.869183 seconds. (cache Word Embeddings)\n",
    "# Extract Features process took 0:00:06.143361 seconds. (cache Doc2Vec)\n",
    "# Extract Features process took 0:00:01.308678 seconds. (improved computation for bag of character features)\n",
    "# Extract Features process took 0:00:01.259591 seconds. (smaller optimisation tweaks - string cat, removal of double compute of some stats)\n",
    "# Extract Features process took 0:00:00.650005 seconds. (use arrays not pd.Series for stats, series.str.count is also inefficient compared to loops)\n",
    "# Extract Features process took 0:00:00.320845 seconds. (replace np stats calcs, unique values calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_[0]-agg-any  n_[0]-agg-all  n_[0]-agg-mean  n_[0]-agg-var  \\\n",
      "0             0.0            0.0           0.000       0.000000   \n",
      "1             0.0            0.0           0.000       0.000000   \n",
      "2             0.0            0.0           0.000       0.000000   \n",
      "3             0.0            0.0           0.000       0.000000   \n",
      "4             0.0            0.0           0.000       0.000000   \n",
      "5             0.0            0.0           0.000       0.000000   \n",
      "6             0.0            0.0           0.000       0.000000   \n",
      "7             0.0            0.0           0.000       0.000000   \n",
      "8             1.0            0.0           2.133       0.871311   \n",
      "9             0.0            0.0           0.000       0.000000   \n",
      "10            0.0            0.0           0.000       0.000000   \n",
      "11            1.0            0.0           0.079       0.072759   \n",
      "12            0.0            0.0           0.000       0.000000   \n",
      "13            1.0            0.0           0.155       0.130975   \n",
      "14            0.0            0.0           0.000       0.000000   \n",
      "15            0.0            0.0           0.000       0.000000   \n",
      "16            0.0            0.0           0.000       0.000000   \n",
      "17            1.0            0.0           0.377       0.342871   \n",
      "18            0.0            0.0           0.000       0.000000   \n",
      "19            0.0            0.0           0.000       0.000000   \n",
      "\n",
      "    n_[0]-agg-min  n_[0]-agg-max  n_[0]-agg-median  n_[0]-agg-sum  \\\n",
      "0             0.0            0.0               0.0            0.0   \n",
      "1             0.0            0.0               0.0            0.0   \n",
      "2             0.0            0.0               0.0            0.0   \n",
      "3             0.0            0.0               0.0            0.0   \n",
      "4             0.0            0.0               0.0            0.0   \n",
      "5             0.0            0.0               0.0            0.0   \n",
      "6             0.0            0.0               0.0            0.0   \n",
      "7             0.0            0.0               0.0            0.0   \n",
      "8             0.0            6.0               2.0         2133.0   \n",
      "9             0.0            0.0               0.0            0.0   \n",
      "10            0.0            0.0               0.0            0.0   \n",
      "11            0.0            1.0               0.0           79.0   \n",
      "12            0.0            0.0               0.0            0.0   \n",
      "13            0.0            1.0               0.0          155.0   \n",
      "14            0.0            0.0               0.0            0.0   \n",
      "15            0.0            0.0               0.0            0.0   \n",
      "16            0.0            0.0               0.0            0.0   \n",
      "17            0.0            3.0               0.0          377.0   \n",
      "18            0.0            0.0               0.0            0.0   \n",
      "19            0.0            0.0               0.0            0.0   \n",
      "\n",
      "    n_[0]-agg-kurtosis  n_[0]-agg-skewness  ...  par_vec_390  par_vec_391  \\\n",
      "0            -3.000000            0.000000  ...    -0.584473     0.126260   \n",
      "1            -3.000000            0.000000  ...    -0.003133     0.147110   \n",
      "2            -3.000000            0.000000  ...    -0.349645     0.122602   \n",
      "3            -3.000000            0.000000  ...    -0.006067     0.237623   \n",
      "4            -3.000000            0.000000  ...    -0.397215    -0.145574   \n",
      "5            -3.000000            0.000000  ...    -0.808584     0.791327   \n",
      "6            -3.000000            0.000000  ...    -0.029990    -0.219640   \n",
      "7            -3.000000            0.000000  ...    -0.028366     0.483343   \n",
      "8             0.118893            0.611071  ...    -0.000470    -0.000460   \n",
      "9            -3.000000            0.000000  ...    -0.030477     0.182648   \n",
      "10           -3.000000            0.000000  ...     0.000284     0.000113   \n",
      "11            7.744004            3.121539  ...    -0.177324     0.288716   \n",
      "12           -3.000000            0.000000  ...    -0.583529     0.125164   \n",
      "13            1.635045            1.906579  ...    -0.302009     0.568736   \n",
      "14           -3.000000            0.000000  ...    -0.196956     0.065468   \n",
      "15           -3.000000            0.000000  ...     0.171240     0.311294   \n",
      "16           -3.000000            0.000000  ...    -0.031093     0.486765   \n",
      "17            1.565252            1.412721  ...     0.000802    -0.000522   \n",
      "18           -3.000000            0.000000  ...     0.720182     0.703355   \n",
      "19           -3.000000            0.000000  ...    -0.418924     0.979715   \n",
      "\n",
      "    par_vec_392  par_vec_393  par_vec_394  par_vec_395  par_vec_396  \\\n",
      "0      0.096125     0.023798     0.636748     0.365483     0.538049   \n",
      "1      0.123854     0.303699     0.635650     0.220293     0.156203   \n",
      "2      0.643925    -0.335219     0.076710     1.761140     0.937366   \n",
      "3      0.667017    -0.583059     0.365096     1.463040     0.962245   \n",
      "4      0.283310    -0.059998    -0.062417     1.211720     0.806465   \n",
      "5     -0.455287    -0.015427     0.543918     0.306637     0.076077   \n",
      "6      0.109829     0.073197    -0.461185     1.060420    -0.723453   \n",
      "7      0.158517     0.069841     0.414757     0.398196     0.668308   \n",
      "8     -0.000376     0.000040    -0.000230    -0.000495    -0.000132   \n",
      "9      0.125173     0.281233     0.638843     0.230276     0.170218   \n",
      "10    -0.000910     0.000570     0.000846    -0.000877    -0.001144   \n",
      "11    -0.850912     0.102648    -0.712009     0.257658    -0.452656   \n",
      "12     0.097425     0.024281     0.637573     0.367198     0.538113   \n",
      "13    -0.298638     0.102913     0.153100     0.359782     0.163035   \n",
      "14     0.006171    -0.059564    -0.006217     0.044210     0.180631   \n",
      "15    -0.042579    -0.141542     0.293827     0.997714     0.335226   \n",
      "16     0.155751     0.070462     0.415175     0.400056     0.672875   \n",
      "17    -0.000828    -0.001100    -0.001039    -0.000024    -0.000679   \n",
      "18    -0.354511     0.114508    -0.147446     0.326658     1.341010   \n",
      "19     0.139074     0.484003    -0.360446    -0.054635     0.877968   \n",
      "\n",
      "    par_vec_397  par_vec_398  par_vec_399  \n",
      "0     -0.405966     0.882651     0.189909  \n",
      "1     -0.029888     0.609212    -0.169265  \n",
      "2     -0.100498     0.658801    -0.418056  \n",
      "3     -0.222023     0.956106    -0.485072  \n",
      "4     -0.343072     0.696445    -0.560752  \n",
      "5     -0.488103     1.550690    -0.701052  \n",
      "6     -1.758400     1.542490     0.336616  \n",
      "7     -0.264600     1.149530     0.179544  \n",
      "8      0.000517     0.000291     0.000688  \n",
      "9     -0.040337     0.613233    -0.148885  \n",
      "10    -0.000118     0.000073     0.000711  \n",
      "11    -0.798165    -0.304771     0.192267  \n",
      "12    -0.410001     0.884598     0.192784  \n",
      "13    -0.080470     0.791702     0.124635  \n",
      "14    -0.047076     0.364031    -0.228381  \n",
      "15    -1.014010     1.152380    -0.080395  \n",
      "16    -0.264412     1.152530     0.182872  \n",
      "17    -0.000266    -0.000753    -0.000319  \n",
      "18    -0.535376     1.815170    -0.086823  \n",
      "19    -0.383130     0.937573    -0.204831  \n",
      "\n",
      "[20 rows x 1578 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('output2.csv', dtype=np.float32)\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0209 12:06:03.123449 4366253568 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0209 12:06:03.124521 4366253568 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0209 12:06:03.128082 4366253568 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0209 12:06:03.148771 4366253568 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = predict_sherlock(X_test, nn_id='retrained_sherlock10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender' 'gender' 'class' 'class' 'class' 'brand' 'company' 'type'\n",
      " 'address' 'gender' 'address' 'age' 'gender' 'address' 'country'\n",
      " 'description' 'type' 'address' 'product' 'description']\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={}\n",
    "\n",
    "labels['product_brandGender2'] = 'gender'\n",
    "labels['product_ageGroup1'] = 'gender'\n",
    "labels['product_sportPurpose3'] = 'description'\n",
    "labels['product_sportPurpose4'] = 'description'\n",
    "labels['product_sportPurpose2'] = 'description'\n",
    "labels['product_brandCategory4_footwear'] = 'description'\n",
    "labels['article_brandColourName'] = 'colour'\n",
    "labels['product_brandCategory1'] = 'category'\n",
    "labels['article_id'] = 'code'\n",
    "labels['product_brandGender1'] = 'gender'\n",
    "labels['product_type'] = 'code'\n",
    "labels['article_brandSize'] = 'code'\n",
    "labels['product_ageGroup2'] = 'gender'\n",
    "labels['product_brandSeason'] = 'code'\n",
    "labels['product_brandSizeGrid'] = 'code'\n",
    "labels['product_sportPurpose1'] = 'description'\n",
    "labels['product_primaryCategoryIdCode'] = 'code'\n",
    "labels['product_id'] = 'code'\n",
    "labels['product_brandCategory3'] = 'category'\n",
    "labels['product_brandCategory2'] = 'category'\n",
    "\n",
    "y_test=list(labels.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27142857142857146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predicted_labels, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
