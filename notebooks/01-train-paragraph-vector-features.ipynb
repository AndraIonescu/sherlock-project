{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need fully deterministic results between runs, set the following environment value prior to launching jupyter.\n",
    "# See comment in sherlock.features.paragraph_vectors.infer_paragraph_embeddings_features for more info.\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training set and train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.features.paragraph_vectors import (\n",
    "    initialise_nltk,\n",
    "    tagcol_paragraph_embeddings_features,\n",
    "    train_paragraph_embeddings_features\n",
    ")\n",
    "from sherlock.features.preprocessing import convert_string_lists_to_lists\n",
    "from sherlock.functional import extract_features_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-09 18:32:07.924777\n"
     ]
    }
   ],
   "source": [
    "print(f'Started at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and read in raw data\n",
    "\n",
    "You can skip this step if you want to use a preprocessed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the raw and preprocessed data into ../data/data.zip.\n",
      "Downloading data directory.\n",
      "Downloading 1-g0zbKFAXz7zKZc0Dnh74uDBpZCv4YqU into ../data/data.zip... \n",
      "3.6 GiB iB                                                                                                                                                                            Done.\n",
      "Unzipping...Done.\n",
      "Data was downloaded.\n"
     ]
    }
   ],
   "source": [
    "helpers.download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = pd.read_parquet('../data/data/raw/train_values.parquet')\n",
    "train_labels = pd.read_parquet('../data/data/raw/train_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412059/412059 [00:57<00:00, 7108.44it/s] \n"
     ]
    }
   ],
   "source": [
    "train_samples_converted, y_train = convert_string_lists_to_lists(train_samples, train_labels, \"values\", \"type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised NLTK, process took 0:00:00.343083 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/madelon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/madelon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: <class 'pandas.core.series.Series'>, length=412059\n",
      "Labels:  <class 'numpy.ndarray'>, length=412059\n"
     ]
    }
   ],
   "source": [
    "samples = train_samples_converted.dropna()\n",
    "print(f'Samples: {type(samples)}, length={len(samples)}')\n",
    "\n",
    "labels = train_labels.values.flatten()\n",
    "print(f'Labels:  {type(labels)}, length={len(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging columns\n",
      "Tagged Columns Doc2Vec Model, process took 0:03:44.321182 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "print('Tagging columns')\n",
    "cols = tagcol_paragraph_embeddings_features(samples, labels)\n",
    "\n",
    "print(f'Tagged Columns Doc2Vec Model, process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec model in 400 dimensions\n",
      "Trained Doc2Vec Model, 400 dim, process took 0:22:22.303905 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "vec_dim = 400\n",
    "print(f'Training Doc2Vec model in {vec_dim} dimensions')\n",
    "\n",
    "train_paragraph_embeddings_features(cols, vec_dim)\n",
    "\n",
    "print(f'Trained Doc2Vec Model, {vec_dim} dim, process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at 2022-02-09 19:38:41.865764\n"
     ]
    }
   ],
   "source": [
    "print(f'Finished at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
