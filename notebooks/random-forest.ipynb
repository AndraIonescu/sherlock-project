{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need fully deterministic results between runs, set the following environment value prior to launching jupyter.\n",
    "# See comment in sherlock.features.paragraph_vectors.infer_paragraph_embeddings_features for more info.\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier \n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-07 15:46:02.658556\n",
      "Load data (train) process took 0:00:04.837128 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('train.parquet')\n",
    "y_train = pd.read_parquet('../data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-07 15:46:07.682626\n",
      "Load data (validation) process took 0:00:01.803970 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([x.lower() for x in itertools.chain(y_train, y_validation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Voting Classifier using RFC and ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-07 15:46:11.682256\n",
      "Finished at 2022-02-07 16:01:59.050932, took 0:15:47.368743 seconds\n"
     ]
    }
   ],
   "source": [
    "# n_estimators=300 gives a slightly better result (0.1%), but triples the fit time\n",
    "voting_clf = VotingClassifier(estimators=[('rf', RandomForestClassifier(n_estimators=100, random_state=13, n_jobs=-1)),\n",
    "                                          ('et', ExtraTreesClassifier(n_estimators=100, random_state=13, n_jobs=-1))],\n",
    "                              voting='soft')\n",
    "\n",
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make individual (trained) estimators available\n",
    "rf_clf = voting_clf.estimators_[0]\n",
    "et_clf = voting_clf.estimators_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-07 16:01:59.120891\n",
      "Trained and saved new model.\n",
      "Finished at 2022-02-07 16:02:00.975332, took 0:00:01.854455 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('test.parquet')\n",
    "y_test = pd.read_parquet('../data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock_proba, _transform_predictions_to_classes\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load(\n",
    "        f\"../sherlock/deploy/classes_{nn_model_id}.npy\",\n",
    "        allow_pickle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (classes == sorted(classes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def predicted_labels(y_pred_proba, classes):\n",
    "    y_pred_int = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = classes\n",
    "\n",
    "    return encoder.inverse_transform(y_pred_int)\n",
    "\n",
    "\n",
    "def prediction_summary(y_test, predicted_labels):\n",
    "    print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "    size=len(y_test)\n",
    "\n",
    "    print(f'f1 score {f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rfc_proba = rf_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8909529156786774\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_rfc_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_etc_proba = et_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8884613184751746\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_etc_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Voting Classifier (RFC + ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_voting_proba = voting_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8933550546229518\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_voting_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Sherlock NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0207 16:02:52.102345 4654583296 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0207 16:02:52.104378 4654583296 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0207 16:02:52.108886 4654583296 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0207 16:02:52.138780 4654583296 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "2022-02-07 16:02:52.704754: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-02-07 16:02:52.762490: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc083ef6bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-07 16:02:52.762507: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "predicted_sherlock_proba = predict_sherlock_proba(X_test, nn_id=nn_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8940572197723697\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_sherlock_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "    \n",
    "for i in range(len(y_test)):\n",
    "    nn_probs = predicted_sherlock_proba[i]\n",
    "    voting_probs = predicted_voting_proba[i]\n",
    "    \n",
    "    x = nn_probs + voting_probs\n",
    "    x = x / 2\n",
    "\n",
    "    combined.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.9047220789717997\n"
     ]
    }
   ],
   "source": [
    "labels = predicted_labels(combined, classes)\n",
    "\n",
    "prediction_summary(y_test, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_table(class_scores):\n",
    "    print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "    for key, value in class_scores:\n",
    "        if len(key) >= 8:\n",
    "            tabs = '\\t' * 1\n",
    "        else:\n",
    "            tabs = '\\t' * 2\n",
    "\n",
    "        print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "grades\t\t0.994\t\t0.994\t\t0.994\t\t1765\n",
      "isbn\t\t0.991\t\t0.993\t\t0.989\t\t1430\n",
      "jockey\t\t0.986\t\t0.980\t\t0.991\t\t2819\n",
      "industry\t0.983\t\t0.979\t\t0.988\t\t2958\n",
      "birth date\t0.978\t\t0.981\t\t0.975\t\t479\n"
     ]
    }
   ],
   "source": [
    "score_table(class_scores[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "rank\t\t0.751\t\t0.710\t\t0.796\t\t2983\n",
      "person\t\t0.690\t\t0.702\t\t0.679\t\t579\n",
      "sales\t\t0.633\t\t0.747\t\t0.550\t\t322\n",
      "director\t0.598\t\t0.648\t\t0.556\t\t225\n",
      "ranking\t\t0.594\t\t0.855\t\t0.456\t\t439\n"
     ]
    }
   ],
   "source": [
    "score_table(class_scores[len(class_scores)-5:len(class_scores)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores (by class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       address      0.926     0.947     0.937      3003\n",
      "     affiliate      0.976     0.814     0.888       204\n",
      "   affiliation      0.978     0.958     0.968      1768\n",
      "           age      0.882     0.963     0.921      3033\n",
      "         album      0.883     0.901     0.892      3035\n",
      "          area      0.888     0.840     0.863      1987\n",
      "        artist      0.807     0.886     0.845      3043\n",
      "    birth date      0.981     0.975     0.978       479\n",
      "   birth place      0.974     0.904     0.938       418\n",
      "         brand      0.795     0.723     0.757       574\n",
      "      capacity      0.879     0.746     0.807       362\n",
      "      category      0.913     0.901     0.907      3087\n",
      "          city      0.857     0.912     0.883      2966\n",
      "         class      0.906     0.926     0.916      2971\n",
      "classification      0.955     0.867     0.909       587\n",
      "          club      0.972     0.961     0.967      2977\n",
      "          code      0.921     0.925     0.923      2956\n",
      "    collection      0.968     0.943     0.955       476\n",
      "       command      0.933     0.930     0.931      1045\n",
      "       company      0.890     0.904     0.897      3041\n",
      "     component      0.893     0.895     0.894      1226\n",
      "     continent      0.908     0.916     0.912       227\n",
      "       country      0.896     0.952     0.923      3038\n",
      "        county      0.938     0.963     0.950      2959\n",
      "       creator      0.848     0.839     0.843       347\n",
      "        credit      0.894     0.823     0.857       941\n",
      "      currency      0.982     0.968     0.975       405\n",
      "           day      0.944     0.915     0.929      3038\n",
      "         depth      0.959     0.944     0.952       947\n",
      "   description      0.795     0.886     0.838      3042\n",
      "      director      0.648     0.556     0.598       225\n",
      "      duration      0.948     0.953     0.950      3000\n",
      "     education      0.902     0.853     0.877       313\n",
      "     elevation      0.953     0.960     0.956      1299\n",
      "        family      0.970     0.903     0.935       746\n",
      "     file size      0.925     0.886     0.905       361\n",
      "        format      0.977     0.957     0.967      2956\n",
      "        gender      0.859     0.834     0.846      1030\n",
      "         genre      0.968     0.948     0.958      1163\n",
      "        grades      0.994     0.994     0.994      1765\n",
      "      industry      0.979     0.988     0.983      2958\n",
      "          isbn      0.993     0.989     0.991      1430\n",
      "        jockey      0.980     0.991     0.986      2819\n",
      "      language      0.927     0.945     0.936      1474\n",
      "      location      0.877     0.844     0.860      2949\n",
      "  manufacturer      0.904     0.798     0.848       945\n",
      "          name      0.788     0.725     0.755      3017\n",
      "   nationality      0.853     0.738     0.791       424\n",
      "         notes      0.779     0.832     0.804      2303\n",
      "      operator      0.850     0.854     0.852       404\n",
      "         order      0.891     0.863     0.877      1462\n",
      "  organisation      0.873     0.817     0.844       262\n",
      "        origin      0.964     0.899     0.930      1439\n",
      "         owner      0.935     0.877     0.905      1673\n",
      "        person      0.702     0.679     0.690       579\n",
      "         plays      0.826     0.919     0.870      1513\n",
      "      position      0.842     0.856     0.849      3057\n",
      "       product      0.865     0.893     0.879      2647\n",
      "     publisher      0.897     0.918     0.907       880\n",
      "         range      0.917     0.801     0.855       577\n",
      "          rank      0.710     0.796     0.751      2983\n",
      "       ranking      0.855     0.456     0.594       439\n",
      "        region      0.894     0.850     0.871      2740\n",
      "      religion      0.975     0.932     0.953       340\n",
      "   requirement      0.938     0.807     0.867       300\n",
      "        result      0.969     0.948     0.958      2920\n",
      "         sales      0.747     0.550     0.633       322\n",
      "       service      0.978     0.925     0.951      2222\n",
      "           sex      0.939     0.940     0.939      2997\n",
      "       species      0.919     0.954     0.936       819\n",
      "         state      0.942     0.960     0.951      3030\n",
      "        status      0.957     0.939     0.948      3100\n",
      "        symbol      0.964     0.967     0.966      1752\n",
      "          team      0.878     0.867     0.873      3011\n",
      "     team name      0.912     0.840     0.875      1639\n",
      "          type      0.888     0.894     0.891      2909\n",
      "        weight      0.946     0.951     0.949      2963\n",
      "          year      0.969     0.941     0.955      3015\n",
      "\n",
      "      accuracy                          0.905    137353\n",
      "     macro avg      0.904     0.880     0.890    137353\n",
      "  weighted avg      0.906     0.905     0.905    137353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches: 13058 (F1 score: 0.9047220789717997)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('name', 830),\n",
       " ('rank', 608),\n",
       " ('location', 460),\n",
       " ('position', 441),\n",
       " ('region', 412),\n",
       " ('team', 399),\n",
       " ('notes', 388),\n",
       " ('artist', 348),\n",
       " ('description', 347),\n",
       " ('area', 318),\n",
       " ('type', 307),\n",
       " ('category', 307),\n",
       " ('album', 299),\n",
       " ('company', 291),\n",
       " ('product', 283),\n",
       " ('team name', 262),\n",
       " ('city', 261),\n",
       " ('day', 258),\n",
       " ('ranking', 239),\n",
       " ('code', 222),\n",
       " ('class', 220),\n",
       " ('owner', 205),\n",
       " ('order', 200),\n",
       " ('manufacturer', 191),\n",
       " ('status', 190),\n",
       " ('person', 186),\n",
       " ('sex', 181),\n",
       " ('year', 177),\n",
       " ('gender', 171),\n",
       " ('credit', 167),\n",
       " ('service', 167),\n",
       " ('brand', 159),\n",
       " ('address', 158),\n",
       " ('result', 151),\n",
       " ('country', 147),\n",
       " ('origin', 146),\n",
       " ('weight', 145),\n",
       " ('sales', 145),\n",
       " ('duration', 140),\n",
       " ('component', 129),\n",
       " ('format', 126),\n",
       " ('plays', 123),\n",
       " ('state', 121),\n",
       " ('club', 116),\n",
       " ('range', 115),\n",
       " ('nationality', 111),\n",
       " ('age', 111),\n",
       " ('county', 110),\n",
       " ('director', 100),\n",
       " ('capacity', 92),\n",
       " ('language', 81),\n",
       " ('classification', 78),\n",
       " ('affiliation', 75),\n",
       " ('command', 73),\n",
       " ('family', 72),\n",
       " ('publisher', 72),\n",
       " ('genre', 60),\n",
       " ('operator', 59),\n",
       " ('requirement', 58),\n",
       " ('symbol', 57),\n",
       " ('creator', 56),\n",
       " ('depth', 53),\n",
       " ('elevation', 52),\n",
       " ('organisation', 48),\n",
       " ('education', 46),\n",
       " ('file size', 41),\n",
       " ('birth place', 40),\n",
       " ('affiliate', 38),\n",
       " ('species', 38),\n",
       " ('industry', 36),\n",
       " ('collection', 27),\n",
       " ('jockey', 25),\n",
       " ('religion', 23),\n",
       " ('continent', 19),\n",
       " ('isbn', 16),\n",
       " ('currency', 13),\n",
       " ('birth date', 12),\n",
       " ('grades', 10)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "#        if k1 in ('brand'):\n",
    "#        print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"age\", actual label \"position\". Actual values:\n",
      "[[2, 4]]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "idx = 541\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed at 2022-02-07 16:03:14.044571\n"
     ]
    }
   ],
   "source": [
    "print(f'Completed at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
