{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need fully deterministic results between runs, set the following environment value prior to launching jupyter.\n",
    "# See comment in sherlock.features.paragraph_vectors.infer_paragraph_embeddings_features for more info.\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier \n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-04 15:57:34.332790\n",
      "Load data (train) process took 0:00:04.621908 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('train.parquet')\n",
    "y_train = pd.read_parquet('../data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-04 15:57:39.131117\n",
      "Load data (validation) process took 0:00:01.841641 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([x.lower() for x in itertools.chain(y_train, y_validation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Voting Classifier using RFC and ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-04 15:57:43.439013\n",
      "Finished at 2022-02-04 16:14:04.419455, took 0:16:20.980509 seconds\n"
     ]
    }
   ],
   "source": [
    "# n_estimators=300 gives a slightly better result (0.1%), but triples the fit time\n",
    "voting_clf = VotingClassifier(estimators=[('rf', RandomForestClassifier(n_estimators=100, random_state=13, n_jobs=-1)),\n",
    "                                          ('et', ExtraTreesClassifier(n_estimators=100, random_state=13, n_jobs=-1))],\n",
    "                              voting='soft')\n",
    "\n",
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make individual (trained) estimators available\n",
    "rf_clf = voting_clf.estimators_[0]\n",
    "et_clf = voting_clf.estimators_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-04 16:14:04.488709\n",
      "Trained and saved new model.\n",
      "Finished at 2022-02-04 16:14:06.346092, took 0:00:01.857398 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('test.parquet')\n",
    "y_test = pd.read_parquet('../data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock_proba, _transform_predictions_to_classes\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load(\n",
    "        f\"../sherlock/deploy/classes_{nn_model_id}.npy\",\n",
    "        allow_pickle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (classes == sorted(classes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def predicted_labels(y_pred_proba, classes):\n",
    "    y_pred_int = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = classes\n",
    "\n",
    "    return encoder.inverse_transform(y_pred_int)\n",
    "\n",
    "\n",
    "def prediction_summary(y_test, predicted_labels):\n",
    "    print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "    size=len(y_test)\n",
    "\n",
    "    print(f'f1 score {f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rfc_proba = rf_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8909529156786774\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_rfc_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_etc_proba = et_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8884613184751746\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_etc_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Voting Classifier (RFC + ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_voting_proba = voting_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8933550546229518\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_voting_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Sherlock NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0204 16:14:58.043523 4490804736 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0204 16:14:58.048420 4490804736 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0204 16:14:58.053483 4490804736 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0204 16:14:58.082564 4490804736 deprecation.py:506] From /Users/lowecg/source/private-github/sherlock-project-1/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "2022-02-04 16:14:58.670711: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-02-04 16:14:58.726360: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8fb44c4b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-04 16:14:58.726381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "predicted_sherlock_proba = predict_sherlock_proba(X_test, nn_id=nn_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8936850535436299\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_sherlock_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "    \n",
    "for i in range(len(y_test)):\n",
    "    nn_probs = predicted_sherlock_proba[i]\n",
    "    voting_probs = predicted_voting_proba[i]\n",
    "    \n",
    "    x = nn_probs + voting_probs\n",
    "    x = x / 2\n",
    "\n",
    "    combined.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.90506986886416\n"
     ]
    }
   ],
   "source": [
    "labels = predicted_labels(combined, classes)\n",
    "\n",
    "prediction_summary(y_test, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_table(class_scores):\n",
    "    print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "    for key, value in class_scores:\n",
    "        if len(key) >= 8:\n",
    "            tabs = '\\t' * 1\n",
    "        else:\n",
    "            tabs = '\\t' * 2\n",
    "\n",
    "        print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "grades\t\t0.993\t\t0.992\t\t0.995\t\t1765\n",
      "isbn\t\t0.991\t\t0.995\t\t0.987\t\t1430\n",
      "jockey\t\t0.987\t\t0.987\t\t0.988\t\t2819\n",
      "industry\t0.984\t\t0.978\t\t0.991\t\t2958\n",
      "currency\t0.979\t\t0.987\t\t0.970\t\t405\n"
     ]
    }
   ],
   "source": [
    "score_table(class_scores[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "rank\t\t0.746\t\t0.702\t\t0.796\t\t2983\n",
      "person\t\t0.707\t\t0.789\t\t0.641\t\t579\n",
      "sales\t\t0.639\t\t0.769\t\t0.547\t\t322\n",
      "director\t0.620\t\t0.686\t\t0.564\t\t225\n",
      "ranking\t\t0.595\t\t0.858\t\t0.456\t\t439\n"
     ]
    }
   ],
   "source": [
    "score_table(class_scores[len(class_scores)-5:len(class_scores)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores (by class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       address      0.939     0.948     0.943      3003\n",
      "     affiliate      0.977     0.824     0.894       204\n",
      "   affiliation      0.979     0.956     0.967      1768\n",
      "           age      0.887     0.958     0.922      3033\n",
      "         album      0.892     0.893     0.892      3035\n",
      "          area      0.908     0.834     0.870      1987\n",
      "        artist      0.815     0.881     0.846      3043\n",
      "    birth date      0.977     0.973     0.975       479\n",
      "   birth place      0.984     0.904     0.943       418\n",
      "         brand      0.779     0.732     0.755       574\n",
      "      capacity      0.863     0.749     0.802       362\n",
      "      category      0.898     0.906     0.902      3087\n",
      "          city      0.847     0.916     0.880      2966\n",
      "         class      0.894     0.926     0.910      2971\n",
      "classification      0.953     0.871     0.910       587\n",
      "          club      0.978     0.957     0.967      2977\n",
      "          code      0.931     0.927     0.929      2956\n",
      "    collection      0.980     0.941     0.960       476\n",
      "       command      0.929     0.932     0.930      1045\n",
      "       company      0.901     0.900     0.901      3041\n",
      "     component      0.888     0.892     0.890      1226\n",
      "     continent      0.907     0.907     0.907       227\n",
      "       country      0.904     0.945     0.924      3038\n",
      "        county      0.951     0.957     0.954      2959\n",
      "       creator      0.902     0.847     0.874       347\n",
      "        credit      0.912     0.824     0.865       941\n",
      "      currency      0.987     0.970     0.979       405\n",
      "           day      0.921     0.924     0.923      3038\n",
      "         depth      0.936     0.946     0.941       947\n",
      "   description      0.835     0.864     0.849      3042\n",
      "      director      0.686     0.564     0.620       225\n",
      "      duration      0.931     0.953     0.942      3000\n",
      "     education      0.920     0.843     0.880       313\n",
      "     elevation      0.953     0.958     0.955      1299\n",
      "        family      0.950     0.909     0.929       746\n",
      "     file size      0.934     0.867     0.899       361\n",
      "        format      0.974     0.959     0.967      2956\n",
      "        gender      0.852     0.841     0.847      1030\n",
      "         genre      0.952     0.955     0.954      1163\n",
      "        grades      0.992     0.995     0.993      1765\n",
      "      industry      0.978     0.991     0.984      2958\n",
      "          isbn      0.995     0.987     0.991      1430\n",
      "        jockey      0.987     0.988     0.987      2819\n",
      "      language      0.893     0.946     0.919      1474\n",
      "      location      0.872     0.842     0.857      2949\n",
      "  manufacturer      0.883     0.828     0.854       945\n",
      "          name      0.734     0.766     0.750      3017\n",
      "   nationality      0.839     0.776     0.806       424\n",
      "         notes      0.751     0.851     0.798      2303\n",
      "      operator      0.839     0.854     0.847       404\n",
      "         order      0.861     0.897     0.879      1462\n",
      "  organisation      0.898     0.844     0.870       262\n",
      "        origin      0.972     0.887     0.928      1439\n",
      "         owner      0.935     0.879     0.906      1673\n",
      "        person      0.789     0.641     0.707       579\n",
      "         plays      0.844     0.917     0.879      1513\n",
      "      position      0.865     0.835     0.850      3057\n",
      "       product      0.878     0.888     0.883      2647\n",
      "     publisher      0.938     0.909     0.923       880\n",
      "         range      0.912     0.790     0.847       577\n",
      "          rank      0.702     0.796     0.746      2983\n",
      "       ranking      0.858     0.456     0.595       439\n",
      "        region      0.881     0.856     0.868      2740\n",
      "      religion      0.987     0.921     0.953       340\n",
      "   requirement      0.964     0.807     0.878       300\n",
      "        result      0.972     0.948     0.960      2920\n",
      "         sales      0.769     0.547     0.639       322\n",
      "       service      0.975     0.929     0.952      2222\n",
      "           sex      0.942     0.936     0.939      2997\n",
      "       species      0.943     0.951     0.947       819\n",
      "         state      0.943     0.958     0.951      3030\n",
      "        status      0.959     0.940     0.949      3100\n",
      "        symbol      0.955     0.970     0.962      1752\n",
      "          team      0.869     0.872     0.871      3011\n",
      "     team name      0.904     0.842     0.872      1639\n",
      "          type      0.901     0.890     0.896      2909\n",
      "        weight      0.965     0.944     0.955      2963\n",
      "          year      0.967     0.943     0.954      3015\n",
      "\n",
      "      accuracy                          0.905    137353\n",
      "     macro avg      0.907     0.880     0.892    137353\n",
      "  weighted avg      0.907     0.905     0.905    137353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches: 13035 (F1 score: 0.90506986886416)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('name', 705),\n",
       " ('rank', 610),\n",
       " ('position', 504),\n",
       " ('location', 466),\n",
       " ('description', 414),\n",
       " ('region', 395),\n",
       " ('team', 385),\n",
       " ('artist', 363),\n",
       " ('notes', 342),\n",
       " ('area', 329),\n",
       " ('album', 325),\n",
       " ('type', 321),\n",
       " ('company', 305),\n",
       " ('product', 297),\n",
       " ('category', 289),\n",
       " ('team name', 259),\n",
       " ('city', 250),\n",
       " ('ranking', 239),\n",
       " ('day', 231),\n",
       " ('class', 219),\n",
       " ('code', 216),\n",
       " ('person', 208),\n",
       " ('owner', 202),\n",
       " ('sex', 192),\n",
       " ('status', 185),\n",
       " ('year', 173),\n",
       " ('country', 166),\n",
       " ('credit', 166),\n",
       " ('weight', 165),\n",
       " ('gender', 164),\n",
       " ('manufacturer', 163),\n",
       " ('origin', 162),\n",
       " ('service', 157),\n",
       " ('address', 156),\n",
       " ('brand', 154),\n",
       " ('result', 153),\n",
       " ('order', 150),\n",
       " ('sales', 146),\n",
       " ('duration', 141),\n",
       " ('component', 132),\n",
       " ('county', 128),\n",
       " ('club', 127),\n",
       " ('state', 126),\n",
       " ('age', 126),\n",
       " ('plays', 125),\n",
       " ('range', 121),\n",
       " ('format', 121),\n",
       " ('director', 98),\n",
       " ('nationality', 95),\n",
       " ('capacity', 91),\n",
       " ('publisher', 80),\n",
       " ('language', 79),\n",
       " ('affiliation', 78),\n",
       " ('classification', 76),\n",
       " ('command', 71),\n",
       " ('family', 68),\n",
       " ('operator', 59),\n",
       " ('requirement', 58),\n",
       " ('elevation', 55),\n",
       " ('creator', 53),\n",
       " ('symbol', 53),\n",
       " ('genre', 52),\n",
       " ('depth', 51),\n",
       " ('education', 49),\n",
       " ('file size', 48),\n",
       " ('organisation', 41),\n",
       " ('birth place', 40),\n",
       " ('species', 40),\n",
       " ('affiliate', 36),\n",
       " ('jockey', 35),\n",
       " ('collection', 28),\n",
       " ('industry', 28),\n",
       " ('religion', 27),\n",
       " ('continent', 21),\n",
       " ('isbn', 18),\n",
       " ('birth date', 13),\n",
       " ('currency', 12),\n",
       " ('grades', 9)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "#        if k1 in ('brand'):\n",
    "#        print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"age\", actual label \"position\". Actual values:\n",
      "[[2, 4]]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "idx = 541\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed at 2022-02-04 16:15:20.833970\n"
     ]
    }
   ],
   "source": [
    "print(f'Completed at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
